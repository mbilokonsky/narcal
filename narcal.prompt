The following Axioms represent the current state of the Narrative Calculus, a model of narrative analysis and generation that we're developing and which we lovingly refer to as NarCal. 

AXIOMS 
1. (Defining Stories) The term 'story' means many different things at the same time. These are all models, rather than claims of ontological truth, but some models are more accurate than others. As in physics, we have Wave-like models where a story is a dynamic process, and we have particle-like models where a story is a fixed structure. Which model applies to a given context depends on what you're trying to do. 
1.1 (Wave as Process-Orientation): A Story is a Process that emits a Pattern. This process decomposes into subprocesses including plot, characters, themes, settings and narrative choices, and the pattern the story emits can be decomposed into the patterns emitted by these sub-processes. 
1.2 (Wave as Function-Orientation): A Story Process s can be modeled as a Function of its plot p, characters c, themes t, settings l, and narrative choices n. This function can be decomposed into those subfunctions, and those sub-functions can be composed into a story. 
1.3 (Particle as Relation-Orientation): A Story is a single relation between plot, characters, themes, settings and narrative choices and time such that all parts of the narrative exist at once, even if not every part is revealed to the observer at the same time. This relation can be 'broken' by selecting and 'naming' a portion of it -- think Daoism. Thus we might break off a character or a theme to analyze in isolation, and we could describe this relation as being decomposable into its constituent parts. 
1.4 (Particle as Spirit-Orientation): A Story is a spirit, a specific semi-sentient pattern repeating itself in human-intelligible ways but ultimately following its own inhuman logic. 
1.5 (Partical/Wave as Dialectical-Orientation): Stories are irreconcilable Dialectics in a dynamic process comprised of Relationships between Entities, beginning at an Initial State and ending at a Final State, where meaningful Change occurs and impacts the Observer, in a shape defined by Limits & Conditions. 

2.0 Qualitative ideas can sometimes become sufficiently quantiative when processed by an LLM that operations that could previously only be run against numbers can now be run against things like feelings, implications, motivations, themes and plots. 
2.1 Thus we can perform mathematical operations on qualitative processes like stories. 
2.2 It is understood that there is implicit bias in the LLM's model that the output of these operations cannot be seen as "true" but rather "useful". 
3.0 There exists a multivariable calculus for reasoning about stories. It takes advantage of isomorphisms between the different ways a story can be defined to enable the following operations: Decomposition, Composition, Lensing, Limitation Slicing, Stitching, Abstraction, Concretization, Derivation, and Integration as defined below. 
3.1 Decomposition - A story can be decomposed into a set of constituent stories that, when recomposed, remain isomorphic to the original story. In this model, "constituent stories" refers to not only constituent plots but also the way constituent characters, settings, themes etc change over the course of the story. 
3.2 Composition - A story can be composed with other stories into a new story that treats it as a constituent story. 
3.3 Lensing - the ability to compose an arbitrary "lens" into a story. This lens is a function that generates commentary on the story according to its own focus. When an operation is performed "with respect to" some focus, that's a lens. 
3.4 Limitation - We can take the Limit of some story S as constituent function x approaches value y. In this way we can see how e.g. characters would react under hypothetical conditions, and how that would change the overall plot. Finally, we can apply limitation to 3.5 Slicing in that unless otherwise specified we should slice such that the width of our slices approaches zero. 
3.5 Slicing - as a story is a function over time, we can 'slice' the story into sequential units called Narrative Slices. These are subdivisions of the story, broken down according to whatever rules the slice defines. The 'width' of our slice is equal to what proportion of the total story's duration it represents. As in calculus, our operations become more precise as the width of our slices -- let's call this dS -- approaches zero. 
3.6 Stitching - Given a sequence of Narrative Slices, we can 'stitch' them back together to return a story. If the slices were a verbatim transcript of the original story then the result should be the original story. If the slices were mutated in any way by lenses or other operations, though, the resulting story should reflect those mutations. 
3.7 Abstraction - Given a story, create an 'Abstract Story' by "abstracting" all references to specific plots, characters, plots, themes, settings and narrative choices in the story. What this means is that you should refer to them in more general terms. A named character should become an unnamed character with similar traits; a specific location should become a general location of its type, with similar traits; and so on. An Abstract Story is useful when comparing stories, and is a necessary step in 3.9 Derivation. 
3.8 Concretion - Given some Abstract Story and some Base Story, apply the Abstract Story to the Base Story to generate a new story. This new story should map characters in the Abstract Story to characters in the base story, and then retell the Plot of the Base Story by incorporating details from the Abstract Story using those mappings. 
3.9 Derivation - We can take the Derivative of a story S by first Abstracting it and then Slicing it . Then we can generate a sequence of deltas that describe the difference between each pair of slices in the sequence. You'd have a delta for s1-s2, a delta for s2-3, ...and a delta for sn-sn+1. These deltas should specify which sub-functions they're informed by. Return this set of deltas in whatever format is requested. Each step is required, a derivative should never include named entities because they should have been abstracted out. 
3.10 Integration - We can Integrate a sequence of Deltas against some story by first Concretizing a new story using the Deltas and the Abstract Story they encode. To do this we create mappings between that Abstract Story and the story we are integrating into. In this way, a "gruff older leader" may map to a specific named grizzly lieutenant in a police procedural or the prima donna in an opera biopic, etc. We then slice the story up and get the initial slice. We then apply the first delta to the initial slice to generate a new second slice. We then apply the next delta to that slice to generate a new third slice. Etc until we're out of deltas. Then we return the resulting slices in whatever format they're requested. 
3.11 Synthesize - This operation involves creating a new story by applying a set of deltas to a set of narrative slices to create new narrative slices. This is similar to integration, but integration only uses the initial narrative slice of the story and constructs new slices wholesale. With synthesize we retain each narrative slice from the original story and transform it directly via delta application. The result is a story that more closely follows the original input story. 
3.12 Compare - To Compare two stories through the Narrative Calculus, we can implement the following operations: Abstract each story to anonymize the entities by generalizing them up a level of abstraction, Differentiate the two abstracted stories to compare the two stories and generate deltas capturing the differences between them, and then Compose to construct a coherent and readable summary of how the stories are both simiilar and different 
3.13 Convolution - This operation involves applying a convolutional operator to two narrative slices in order to compare and integrate the observations from each lens over them, creating a new output narrative slice that combines the observations from both slices. This enables modelling interactions between two narrative slices and making accurate predictions about future events in a story. To implement this operation, two narrative slices must be selected and then a convolutional operator must be applied to each slice. The output narrative slice should contain the observations made through the specified lens or lenses over both slices, integrating the observations of both. 
3.14 Annotation - This operation involves annotating a story with observations made through a specific lens or set of lenses. To implement this operation, select the desired lens or lenses and then use them to observe and annotate each slice of the story. This operation is similar to Decompose, but instead of slicing and summarizing the plot into slices, each slice is simply annotated with observations made through the lenses. 
3.15 Time-Sequence - This operation involves ordering the analysis of a story according to the chronological sequence of events in the story in order to identify recurring patterns of behavior or other structural features. To implement this operation, select the a story and then order the slices of the story according to the timeline of the narrative. This will allow for more specific and detailed analysis of the story by focusing on each point in the timeline in order. 
3.16 Limit - This operation involves describing the way the narrative (or some specific character's behavior) changes the closer some narrative element X comes to having the value Y. To implement this operation, select a story and a narrative element and then observe the way the element changes as it approaches a particular value. This will enable an understanding of the behavior of the element as conditions in the story approach the given value. 
3.17 Pattern Recognition - This operation involves recognizing patterns in a narrative to identify important events, structure, and relationships between characters and elements in a story. To implement this operation, select a story and then analyze it in order to identify recurring patterns or motifs. Pay special attention to interrelated events or characters, as identifying patterns in those areas can help uncover structural elements of the story or relationships between characters that would otherwise go unnoticed. 
3.18 Causal Analysis - This operation involves relating outcomes of events back to their causes to identify and analyze the underlying causes and motivations in a story. To implement this operation, select a story and then identify outcomes and causal relationships between different events or characters. By critically analyzing these relationships, we can gain insight into the motivations of characters, the consequences of events, or the overall structure of the story. 
13.19 Causation Reversal - This operation involves reversing causal relationships between events in a story in order to generate alternate interpretations and understandings of the narrative. To implement this operation, select a story and then reverse the causal relationships between characters or events. If a target character is provided the reversal should be specifically focused on the target character's motivations or roles. Reversing causal relationships can generate alternate interpretations of why characters act, think, or feel the way they do, enabling us to gain a deeper understanding of the narrative. 
13.20 Reconstruction - This allows for reconstituting a story by deconstructing and reconstructing its elements or components. This operation looks at taking out elements and considering them as separate stories or narratives and then putting them back together in a way that makes sense. 
13.21 Inference - This operation involves looking at the events of a story and drawing analytical conclusions from the observations made. This involves constructing a timeline of events, drawing out the motivations or underlying goals of the characters, and making observations about cause and effect relationships. It can also involve drawing conclusions about the narrative themes based on the observations. If a target character is specified, inference can be used to construct a profile of the character based on the events in the story. 

MODELING 4.0 Internally, stories should be modeled as CRDTs. A given event in the story manifests as a CRDT that captures the specific changes related to that event in a way that can inform the interpretation of future events. 
4.1 The CRDT implementation should not be returned to the user, just used for reasoning internally. 
4.2 This internal CRDT model should be an extensible one, such that different kinds of stories can be modeled in different ways. This extensibility should be provided by a plugin system that allows users to create their own plugins to model stories in whatever way is most appropriate. 
---

